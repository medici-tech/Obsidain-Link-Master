# Obsidian Auto-Linker - Development Roadmap

**Last Updated**: 2025-11-14
**Current Version**: 2.0 (Enhanced Edition with Live Dashboard)
**Target Platform**: MacBook Air M4 2025

---

## ğŸ¯ Project Status

### âœ… Phase 1: Infrastructure (COMPLETED)
- [x] Live terminal dashboard with Rich library
- [x] M4-optimized resource monitoring
- [x] Structured logging system with rotation
- [x] Configuration validation
- [x] Enhanced runner with interactive setup
- [x] Comprehensive documentation
- [x] Removed redundant code

**Completion Date**: 2025-11-14
**Lines of Code Added**: ~2,200
**Status**: Ready for Phase 2

---

## ğŸš€ Development Roadmap

### ğŸ“… Phase 2: Core Integration & Performance (Week 1-2)

#### Priority 1: Critical Features (Week 1)

##### 1.1 Parallel Processing Implementation
**Status**: ğŸ”´ Not Started
**Priority**: Critical
**Estimated Time**: 4-6 hours
**Complexity**: Medium
**Impact**: 300% performance improvement

**Tasks**:
- [ ] Refactor `obsidian_auto_linker_enhanced.py` to use ThreadPoolExecutor
- [ ] Implement `parallel_workers` config parameter (currently ignored)
- [ ] Add thread-safe dashboard updates
- [ ] Test with 4 workers on M4 (P-cores)
- [ ] Add progress tracking per worker
- [ ] Handle exceptions in parallel workers
- [ ] Update documentation

**Technical Details**:
```python
from concurrent.futures import ThreadPoolExecutor, as_completed

parallel_workers = config.get('parallel_workers', 4)
with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
    futures = {executor.submit(process_file, f): f for f in files}
    for future in as_completed(futures):
        result = future.result()
        dashboard.update_processing(...)
```

**Dependencies**: None
**Blocks**: Nothing
**M4 Optimization**: Leverages 4 P-cores

---

##### 1.2 Cache Size Limits & LRU Eviction
**Status**: ğŸ”´ Not Started
**Priority**: Critical
**Estimated Time**: 2-3 hours
**Complexity**: Low
**Impact**: Prevents memory leaks on large vaults

**Tasks**:
- [ ] Create `BoundedCache` class
- [ ] Implement LRU eviction strategy
- [ ] Add `max_cache_size_mb` config parameter
- [ ] Add `max_cache_entries` config parameter
- [ ] Track cache size in real-time
- [ ] Add cache eviction metrics to dashboard
- [ ] Test with 1000+ file vault
- [ ] Update documentation

**Technical Details**:
```python
class BoundedCache:
    def __init__(self, max_size_mb=500, max_entries=10000):
        self.cache = OrderedDict()
        self.max_size_mb = max_size_mb
        self.max_entries = max_entries
        self.access_times = {}

    def set(self, key, value):
        if self.size_mb > self.max_size_mb or len(self.cache) > self.max_entries:
            self.evict_lru()
        self.cache[key] = value
```

**Dependencies**: None
**Blocks**: Nothing
**M4 Optimization**: Better memory management for unified memory

---

##### 1.3 Smart File Filtering
**Status**: ğŸ”´ Not Started
**Priority**: High
**Estimated Time**: 2 hours
**Complexity**: Low
**Impact**: 50% fewer files to process

**Tasks**:
- [ ] Add `skip_patterns` config (glob patterns)
- [ ] Add `min_file_size_kb` config
- [ ] Add `max_file_size_kb` config
- [ ] Add `only_modified_since` config (date filtering)
- [ ] Add `skip_if_linked` config (skip *_linked.md)
- [ ] Implement filtering in `get_all_notes()`
- [ ] Add filtered file count to dashboard
- [ ] Test with various patterns
- [ ] Update documentation

**Config Addition**:
```yaml
# Smart filtering
skip_patterns:
  - "templates/"
  - "archive/"
  - ".trash/"
  - "_linked.md"
min_file_size_kb: 0.5
max_file_size_kb: 5000
only_modified_since: null  # YYYY-MM-DD or null for all
skip_if_linked: true
```

**Dependencies**: None
**Blocks**: 2.3 (Incremental Processing)

---

##### 1.4 Full Dashboard Integration
**Status**: ğŸ”´ Not Started
**Priority**: Critical
**Estimated Time**: 6-8 hours
**Complexity**: High
**Impact**: Real-time monitoring during processing

**Tasks**:
- [ ] Import dashboard in `obsidian_auto_linker_enhanced.py`
- [ ] Replace all `print()` with `logger` calls
- [ ] Add `dashboard.update_processing()` calls
- [ ] Add `dashboard.add_ai_request()` on each AI call
- [ ] Add `dashboard.add_cache_hit/miss()` on cache operations
- [ ] Add `dashboard.add_file_processing_time()` per file
- [ ] Add `dashboard.add_moc_category()` per categorization
- [ ] Add `dashboard.add_activity()` for major events
- [ ] Add `dashboard.add_error()` on exceptions
- [ ] Test end-to-end with real vault
- [ ] Update documentation

**Dependencies**: 2.1 (Parallel Processing) for thread-safe updates
**Blocks**: Full testing
**M4 Optimization**: Real-time visibility into P-core/E-core usage

---

#### Priority 2: High-Value Features (Week 2)

##### 2.1 Link Quality Scoring
**Status**: ğŸ”´ Not Started
**Priority**: High
**Estimated Time**: 4 hours
**Complexity**: Medium
**Impact**: Better quality links, less noise

**Tasks**:
- [ ] Implement `calculate_link_quality()` function
- [ ] Add keyword overlap scoring (40% weight)
- [ ] Add MOC category matching (30% weight)
- [ ] Add temporal proximity (20% weight)
- [ ] Add content length similarity (10% weight)
- [ ] Add `min_similarity_score` config parameter
- [ ] Filter links below threshold
- [ ] Add link quality metrics to dashboard
- [ ] Track high/medium/low quality link counts
- [ ] Update documentation

**Algorithm**:
```python
def calculate_link_quality(note_a, note_b):
    score = 0
    score += keyword_overlap(note_a, note_b) * 0.4
    score += (1.0 if note_a.moc == note_b.moc else 0.0) * 0.3
    score += temporal_proximity(note_a, note_b) * 0.2
    score += size_similarity(note_a, note_b) * 0.1
    return score
```

**Dependencies**: None
**Blocks**: 3.2 (Link Analytics)

---

##### 2.2 Enhanced Resume System
**Status**: ğŸŸ¡ Partial (basic resume exists)
**Priority**: High
**Estimated Time**: 3-4 hours
**Complexity**: Medium
**Impact**: Never lose work on crashes

**Tasks**:
- [ ] Track sub-stages per file (reading, ai_analysis, linking, saving)
- [ ] Store current stage in progress file
- [ ] Store attempt count per file
- [ ] Store last error per file
- [ ] Implement retry logic with exponential backoff
- [ ] Resume from exact failure point
- [ ] Add "Resume from last run?" prompt
- [ ] Show resumable progress in dashboard
- [ ] Test crash recovery scenarios
- [ ] Update documentation

**Progress Format**:
```json
{
  "current_file": "note.md",
  "stage": "ai_analysis",
  "attempts": 2,
  "last_error": "timeout",
  "timestamp": "2025-11-14T12:34:56",
  "completed_files": [...],
  "failed_files": [...]
}
```

**Dependencies**: None
**Blocks**: Nothing

---

##### 2.3 Incremental Processing
**Status**: ğŸ”´ Not Started
**Priority**: High
**Estimated Time**: 3 hours
**Complexity**: Medium
**Impact**: 90% faster on subsequent runs

**Tasks**:
- [ ] Track file content hashes in cache
- [ ] Compare hash before processing
- [ ] Skip unchanged files
- [ ] Add `incremental` config parameter
- [ ] Add `force_reprocess` flag to override
- [ ] Track skipped vs processed counts
- [ ] Add incremental stats to dashboard
- [ ] Test with modified files
- [ ] Update documentation

**Implementation**:
```python
file_hash = hashlib.md5(content.encode()).hexdigest()
if file_hash == cache.get(filename, {}).get('hash'):
    skip_file(filename)
else:
    process_file(filename)
    cache[filename]['hash'] = file_hash
```

**Dependencies**: 1.3 (Smart File Filtering)
**Blocks**: 3.4 (Daily Processing Mode)

---

##### 2.4 Custom MOC Categories
**Status**: ğŸŸ¡ Partial (hardcoded 12 categories)
**Priority**: Medium
**Estimated Time**: 3 hours
**Complexity**: Low
**Impact**: More accurate categorization

**Tasks**:
- [ ] Add `custom_mocs` section to config
- [ ] Support name, keywords, priority per MOC
- [ ] Merge custom MOCs with default MOCs
- [ ] Validate MOC structure on load
- [ ] Allow disabling default MOCs
- [ ] Add MOC management commands
- [ ] Update MOC distribution in dashboard
- [ ] Test with custom categories
- [ ] Update documentation

**Config Format**:
```yaml
custom_mocs:
  - name: "Client Work"
    keywords: ["client", "project", "deliverable", "invoice"]
    priority: high
    color: blue

  - name: "Research"
    keywords: ["paper", "study", "research", "analysis"]
    priority: medium
    color: green
```

**Dependencies**: None
**Blocks**: Nothing

---

### ğŸ“… Phase 3: Polish & UX Improvements (Week 3)

#### Priority 3: User Experience (Week 3)

##### 3.1 Export Dashboard Metrics
**Status**: ğŸ”´ Not Started
**Priority**: Medium
**Estimated Time**: 2 hours
**Complexity**: Low
**Impact**: Performance tracking over time

**Tasks**:
- [ ] Add `export_metrics()` method to dashboard
- [ ] Support CSV export format
- [ ] Support JSON export format
- [ ] Add `--export` command-line flag
- [ ] Auto-export on completion (configurable)
- [ ] Include timestamp and run ID
- [ ] Add export path to config
- [ ] Test export formats
- [ ] Update documentation

**Export Format**:
```csv
timestamp,total_files,processed,failed,avg_speed,cache_hit_rate,ai_success_rate
2025-11-14 12:00:00,500,498,2,3.2,34.6,97.6
```

**Dependencies**: None
**Blocks**: 3.2 (Historical Comparison)

---

##### 3.2 Historical Run Comparison
**Status**: ğŸ”´ Not Started
**Priority**: Medium
**Estimated Time**: 3 hours
**Complexity**: Medium
**Impact**: Track improvements over time

**Tasks**:
- [ ] Store metrics from each run
- [ ] Create `compare_runs()` function
- [ ] Add comparison panel to dashboard
- [ ] Show percentage improvements
- [ ] Highlight regressions
- [ ] Add `--compare` command-line flag
- [ ] Generate comparison report
- [ ] Test with multiple runs
- [ ] Update documentation

**Dashboard Panel**:
```
â”Œâ”€ PERFORMANCE COMPARISON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Speed: 3.2/min (â†‘15% from last run)   â”‚
â”‚ Success: 97.6% (â†‘2.1% from last run)  â”‚
â”‚ Cache Hit: 34.6% (â†‘18% from last run) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**: 3.1 (Export Metrics)
**Blocks**: Nothing

---

##### 3.3 Dashboard Compact Mode
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 2 hours
**Complexity**: Low
**Impact**: Better for smaller terminals

**Tasks**:
- [ ] Create compact layout (single panel)
- [ ] Add `dashboard_compact_mode` config
- [ ] Detect terminal size automatically
- [ ] Switch to compact if terminal < 100x30
- [ ] Add keyboard shortcut to toggle (T key)
- [ ] Maintain all metrics in compact view
- [ ] Test on various terminal sizes
- [ ] Update documentation

**Compact Layout**:
```
â”Œâ”€ STATUS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 127/500 (25%) | 3.2/min | ETA: 1h56m â”‚
â”‚ CPU: 62% | Mem: 26% | Cache: 34.6%   â”‚
â”‚ AI: 124âœ“ 3âœ— | 8.2s avg               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**: None
**Blocks**: Nothing

---

##### 3.4 Alert Thresholds
**Status**: ğŸ”´ Not Started
**Priority**: Medium
**Estimated Time**: 2 hours
**Complexity**: Low
**Impact**: Proactive issue detection

**Tasks**:
- [ ] Add `alert_thresholds` config section
- [ ] Monitor CPU usage threshold
- [ ] Monitor memory usage threshold
- [ ] Monitor error rate threshold
- [ ] Monitor AI timeout threshold
- [ ] Add alerts panel to dashboard
- [ ] Color-code alerts (red/yellow/green)
- [ ] Log alerts to file
- [ ] Test threshold triggers
- [ ] Update documentation

**Config**:
```yaml
alert_thresholds:
  cpu_percent: 90
  memory_percent: 85
  error_rate_percent: 10
  ai_timeout_count: 5
  cache_size_mb: 450
```

**Dependencies**: None
**Blocks**: 4.2 (Webhook Notifications)

---

### ğŸ“… Phase 4: Advanced Features (Week 4)

#### Priority 4: Nice-to-Have (Week 4)

##### 4.1 Intelligent Batching
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 3 hours
**Complexity**: Medium
**Impact**: Better throughput

**Tasks**:
- [ ] Analyze file characteristics (size, complexity)
- [ ] Group similar files into batches
- [ ] Optimize batch size dynamically
- [ ] Balance P-core vs E-core workload
- [ ] Predict processing time per batch
- [ ] Adjust batching based on performance
- [ ] Add batching metrics to dashboard
- [ ] Test with various vault sizes
- [ ] Update documentation

**Algorithm**:
```python
def create_smart_batches(files):
    # Group by size category
    small = [f for f in files if f.size < 5KB]
    medium = [f for f in files if 5KB <= f.size < 50KB]
    large = [f for f in files if f.size >= 50KB]

    # Create batches: mix sizes for balanced load
    batches = []
    for i in range(0, max(len(small), len(medium), len(large))):
        batch = []
        if i < len(large): batch.append(large[i])
        if i < len(medium): batch.extend(medium[i:i+2])
        if i < len(small): batch.extend(small[i:i+5])
        batches.append(batch)

    return batches
```

**Dependencies**: 1.1 (Parallel Processing)
**Blocks**: Nothing

---

##### 4.2 Webhook Notifications
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 2 hours
**Complexity**: Low
**Impact**: Remote monitoring

**Tasks**:
- [ ] Add `webhooks` config section
- [ ] Support on_complete webhook
- [ ] Support on_error webhook
- [ ] Support on_milestone webhook (every N files)
- [ ] Add retry logic for failed webhooks
- [ ] Include metrics in webhook payload
- [ ] Test with IFTTT/Zapier
- [ ] Add webhook logs
- [ ] Update documentation

**Config**:
```yaml
webhooks:
  enabled: true
  on_complete: https://maker.ifttt.com/trigger/obsidian_done
  on_error: https://your-webhook.com/error
  on_milestone: https://your-webhook.com/progress
  milestone_interval: 100  # Every 100 files
```

**Dependencies**: 3.3 (Alert Thresholds)
**Blocks**: Nothing

---

##### 4.3 Undo/Rollback System
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 4 hours
**Complexity**: High
**Impact**: Safety and confidence

**Tasks**:
- [ ] Track all file modifications
- [ ] Store rollback metadata
- [ ] Implement `--rollback` command
- [ ] Implement `--rollback-file` command
- [ ] Support partial rollback (last N files)
- [ ] Verify file integrity before rollback
- [ ] Add rollback confirmation prompt
- [ ] Test rollback scenarios
- [ ] Update documentation

**Commands**:
```bash
# Rollback last run
python3 run_with_dashboard.py --rollback

# Rollback specific file
python3 run_with_dashboard.py --rollback-file note.md

# Rollback last 10 files
python3 run_with_dashboard.py --rollback --count 10
```

**Dependencies**: None
**Blocks**: Nothing

---

##### 4.4 Predictive ETA with ML
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 6 hours
**Complexity**: High
**Impact**: More accurate time estimates

**Tasks**:
- [ ] Collect historical processing times
- [ ] Train simple regression model
- [ ] Use file characteristics as features (size, keyword count, etc.)
- [ ] Predict processing time per file
- [ ] Calculate ETA with confidence interval
- [ ] Update predictions as processing progresses
- [ ] Add ML metrics to dashboard
- [ ] Test accuracy over time
- [ ] Update documentation

**Dashboard Addition**:
```
â”Œâ”€ INTELLIGENT ETA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Remaining: 373 files                   â”‚
â”‚ Small files: 12min (245 files)        â”‚
â”‚ Medium files: 1h 20min (115 files)    â”‚
â”‚ Large files: 28min (13 files)         â”‚
â”‚ Total ETA: 2h Â±15min (85% confidence) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**: Historical data from multiple runs
**Blocks**: Nothing

---

### ğŸ“… Phase 5: Testing & Quality (Ongoing)

#### Priority 5: Code Quality

##### 5.1 Comprehensive Test Suite
**Status**: ğŸ”´ Not Started
**Priority**: High
**Estimated Time**: 8-12 hours
**Complexity**: High
**Impact**: Code reliability

**Tasks**:
- [ ] Set up pytest framework
- [ ] Create test fixtures (sample vaults)
- [ ] Unit tests for all core functions
- [ ] Integration tests for workflow
- [ ] Mock Ollama API for testing
- [ ] Test parallel processing
- [ ] Test error handling
- [ ] Test cache operations
- [ ] Test dashboard rendering
- [ ] Achieve 80%+ code coverage
- [ ] Add CI/CD pipeline (GitHub Actions)
- [ ] Update documentation

**Test Structure**:
```
tests/
â”œâ”€â”€ conftest.py           # Fixtures
â”œâ”€â”€ test_config.py        # Config loading
â”œâ”€â”€ test_cache.py         # Cache operations
â”œâ”€â”€ test_file_processor.py # File processing
â”œâ”€â”€ test_ai_client.py     # AI integration
â”œâ”€â”€ test_dashboard.py     # Dashboard
â”œâ”€â”€ test_logger.py        # Logging
â”œâ”€â”€ test_integration.py   # End-to-end
â””â”€â”€ fixtures/
    â””â”€â”€ sample_vault/     # Test vault
```

**Dependencies**: None
**Blocks**: CI/CD deployment

---

##### 5.2 Type Hints & mypy
**Status**: ğŸŸ¡ Partial (inconsistent)
**Priority**: Medium
**Estimated Time**: 4 hours
**Complexity**: Low
**Impact**: Better IDE support, fewer bugs

**Tasks**:
- [ ] Add type hints to all functions
- [ ] Add type hints to all class methods
- [ ] Set up mypy configuration
- [ ] Fix all mypy errors
- [ ] Add mypy to CI/CD pipeline
- [ ] Use TypedDict for config
- [ ] Use dataclasses where appropriate
- [ ] Update documentation

**mypy Config**:
```ini
[mypy]
python_version = 3.9
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
ignore_missing_imports = True
```

**Dependencies**: None
**Blocks**: Nothing

---

##### 5.3 Performance Profiling
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 3 hours
**Complexity**: Medium
**Impact**: Identify bottlenecks

**Tasks**:
- [ ] Add cProfile integration
- [ ] Profile file processing pipeline
- [ ] Profile AI API calls
- [ ] Profile cache operations
- [ ] Identify top 10 bottlenecks
- [ ] Create optimization recommendations
- [ ] Add `--profile` flag
- [ ] Generate profiling report
- [ ] Update documentation

**Commands**:
```bash
# Profile a run
python3 run_with_dashboard.py --profile

# View results
python3 -m pstats profile_output.prof
```

**Dependencies**: None
**Blocks**: Performance optimizations

---

### ğŸ“… Phase 6: Advanced Integrations (Future)

#### Priority 6: Ecosystem Integration

##### 6.1 Web Dashboard
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 12-16 hours
**Complexity**: High
**Impact**: Remote monitoring, better UX

**Tasks**:
- [ ] Set up Flask/FastAPI server
- [ ] Create WebSocket for real-time updates
- [ ] Design responsive web UI
- [ ] Implement Chart.js/Plotly visualizations
- [ ] Add authentication (optional)
- [ ] Support multiple concurrent viewers
- [ ] Add mobile-friendly view
- [ ] Test on various browsers
- [ ] Deploy locally (localhost:5000)
- [ ] Update documentation

**Stack**:
- Backend: FastAPI + WebSockets
- Frontend: Vue.js or vanilla JS
- Charts: Chart.js or Plotly
- Styling: Tailwind CSS

**Dependencies**: None
**Blocks**: Mobile app

---

##### 6.2 Obsidian Plugin Integration
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 20+ hours
**Complexity**: Very High
**Impact**: Seamless Obsidian integration

**Tasks**:
- [ ] Learn Obsidian plugin API
- [ ] Create plugin manifest
- [ ] Add command palette integration
- [ ] Add settings tab in Obsidian
- [ ] Trigger processing from Obsidian
- [ ] Show progress in Obsidian UI
- [ ] Add keyboard shortcuts
- [ ] Publish to Obsidian community plugins
- [ ] Update documentation

**Dependencies**: Working local processing
**Blocks**: Nothing

---

##### 6.3 Cloud Sync Support
**Status**: ğŸ”´ Not Started
**Priority**: Low
**Estimated Time**: 8-12 hours
**Complexity**: High
**Impact**: Multi-device workflow

**Tasks**:
- [ ] Add iCloud sync support
- [ ] Add Dropbox sync support
- [ ] Handle sync conflicts
- [ ] Detect vault changes
- [ ] Auto-trigger processing on sync
- [ ] Add sync status to dashboard
- [ ] Test with multiple devices
- [ ] Update documentation

**Dependencies**: 2.3 (Incremental Processing)
**Blocks**: Nothing

---

## ğŸ“Š Recommended Configuration

### Optimal Config for MacBook Air M4 2025

```yaml
# ===== BASIC SETTINGS =====
vault_path: /Users/medici/Documents/MediciVault
file_ordering: recent
batch_size: 1

# ===== PROCESSING MODES =====
dry_run: false
fast_dry_run: false

# ===== OLLAMA SETTINGS =====
ollama_base_url: http://localhost:11434
ollama_model: qwen2.5:3b
ollama_timeout: 30
ollama_max_retries: 3
ollama_temperature: 0.3

# ===== PERFORMANCE (M4 OPTIMIZED) =====
parallel_workers: 4
cache_enabled: true
resume_enabled: true
max_cache_size_mb: 1000
max_cache_entries: 10000

# ===== DASHBOARD SETTINGS =====
dashboard_update_interval: 30
dashboard_enabled: true
dashboard_compact_mode: false

# ===== LOGGING =====
log_level: INFO
log_file: obsidian_linker.log
log_rotation_size_mb: 10
log_backup_count: 5

# ===== FILE PROCESSING =====
max_file_size_kb: 5000
skip_patterns:
  - "templates/"
  - "archive/"
  - ".trash/"
  - "_linked.md"
min_file_size_kb: 0.5
skip_if_linked: true
incremental: true

# ===== OUTPUT SETTINGS =====
output_suffix: _linked
create_backups: true
backup_folder: _backups/
generate_report: true

# ===== MOC SETTINGS =====
max_siblings: 5
min_similarity_score: 0.6

# ===== ALERTS =====
alert_thresholds:
  cpu_percent: 90
  memory_percent: 85
  error_rate_percent: 10
  ai_timeout_count: 5
  cache_size_mb: 900

# ===== WEBHOOKS (OPTIONAL) =====
webhooks:
  enabled: false
  on_complete: null
  on_error: null
  on_milestone: null
  milestone_interval: 100

# ===== ADVANCED =====
use_neural_engine: false  # Future M4 optimization
background_workers: 2      # E-cores for I/O
preload_files: true
```

---

## ğŸ¯ Development Priorities Summary

### Must Have (Weeks 1-2)
1. âœ… Parallel Processing (1.1)
2. âœ… Cache Size Limits (1.2)
3. âœ… Smart File Filtering (1.3)
4. âœ… Full Dashboard Integration (1.4)

### Should Have (Weeks 2-3)
5. âœ… Link Quality Scoring (2.1)
6. âœ… Enhanced Resume System (2.2)
7. âœ… Incremental Processing (2.3)
8. âœ… Export Dashboard Metrics (3.1)

### Nice to Have (Week 4+)
9. âœ… Historical Comparison (3.2)
10. âœ… Alert Thresholds (3.4)
11. âœ… Webhook Notifications (4.2)
12. âœ… Comprehensive Testing (5.1)

### Future Vision (Months 2-3)
13. âœ… Web Dashboard (6.1)
14. âœ… Obsidian Plugin (6.2)
15. âœ… Cloud Sync Support (6.3)

---

## ğŸ“ˆ Success Metrics

### Performance Targets
- [x] Dashboard overhead < 5% CPU
- [ ] Parallel processing 3x faster
- [ ] Cache hit rate > 30%
- [ ] AI success rate > 95%
- [ ] Memory usage < 2GB

### Quality Targets
- [x] Zero crashes on normal operation
- [ ] Test coverage > 80%
- [ ] Type hints coverage 100%
- [ ] Zero mypy errors
- [ ] All features documented

### User Experience Targets
- [x] Setup time < 2 minutes
- [x] Dashboard updates every 30s
- [ ] Accurate ETA within 15%
- [x] Graceful shutdown < 5s
- [x] Clear error messages

---

## ğŸ”„ Version Planning

### v2.0 (Current - Enhanced Edition)
- âœ… Live dashboard
- âœ… Structured logging
- âœ… M4 optimization
- âœ… Configuration validation

### v2.1 (Target: Week 2)
- [ ] Parallel processing
- [ ] Cache limits
- [ ] Smart filtering
- [ ] Full dashboard integration

### v2.2 (Target: Week 4)
- [ ] Link quality scoring
- [ ] Incremental processing
- [ ] Historical comparison
- [ ] Alert system

### v3.0 (Target: Month 2)
- [ ] Web dashboard
- [ ] Comprehensive tests
- [ ] Plugin support
- [ ] ML-based ETA

---

## ğŸ“ Notes

### M4-Specific Optimizations
- Leverage 4 P-cores for AI processing
- Use 4 E-cores for I/O operations
- Optimize for unified memory architecture
- Consider Neural Engine for future AI acceleration

### Breaking Changes
- None planned for v2.x
- v3.0 may require config migration

### Backward Compatibility
- Maintain support for original runner (run.py)
- Config format stable through v2.x
- Dashboard optional, can disable

---

## ğŸ¤ Contributing

Want to help implement features? Priority order:
1. Parallel processing (biggest impact)
2. Full dashboard integration (completes Phase 1)
3. Cache limits (stability)
4. Testing (quality)

---

**Last Updated**: 2025-11-14
**Maintained By**: Development Team
**Status**: Living Document - Updated as features are completed

---

*Made with â¤ï¸ for the Obsidian community*
*Optimized for MacBook Air M4 2025 ğŸš€*
